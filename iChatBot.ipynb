{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.ops.rnn_cell import GRUCell\n",
    "from tensorflow.python.ops.rnn_cell import LSTMCell\n",
    "from tensorflow.python.ops.rnn_cell import MultiRNNCell\n",
    "from tensorflow.python.ops.rnn_cell import DropoutWrapper, ResidualWrapper\n",
    "\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.util import nest\n",
    "\n",
    "from tensorflow.contrib.seq2seq.python.ops import attention_wrapper\n",
    "from tensorflow.contrib.seq2seq.python.ops import beam_search_decoder\n",
    "\n",
    "from preprocess import *\n",
    "from loading_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetter\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding parameters\n",
    "embedding_size = 50\n",
    "vocab_size = 400003\n",
    "\n",
    "#data parameters\n",
    "eMax_allowed_length = 20\n",
    "dMax_allowed_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching data\n",
    "#default directory: 'data/data_10.csv'\n",
    "X,Y= read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching glove vectors\n",
    "#default directory: \"./glove.6B.50d.txt\"\n",
    "embedding_size = 50\n",
    "wi,iw,wv = read_glove_vecs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding extra tokens to glove dictionary\n",
    "go_index,eos_index,unk_index = add_extra_to_dict(wi,iw,wv,embedding_size)\n",
    "emb = map_dict_to_list(iw,wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data\n",
    "#Mapping each word in a sentence to its glove index\n",
    "eInput,eLengths = fit_encoder_text(data= X[1:],word_to_index = wi,max_allowed_seq_length = eMax_allowed_length)\n",
    "dInput,dOutput,dLengths = fit_decoder_text(data= Y[1:],word_to_index = wi,max_allowed_seq_length = dMax_allowed_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel():\n",
    "    def __init__(self,mode,enc_depth,hidden_units,mydtype):\n",
    "        assert mode.lower() in ['train','decode']\n",
    "        \n",
    "        self.mode = mode.lower()\n",
    "        self.depth = enc_depth\n",
    "        self.hidden_units=hidden_units\n",
    "        self.dtype = tf.float16 if mydtype else tf.float32\n",
    "\n",
    "        '''\n",
    "        self.config = config\n",
    "        \n",
    "        \n",
    "        self.cell_type = config['cell_type']\n",
    "        self.hidden_units = config['hidden_units']\n",
    "        self.depth = config['depth']\n",
    "        self.attention_type = config['attention_type']\n",
    "        self.embedding_size = config['embedding_size']\n",
    "        \n",
    "        self.num_encoder_symbols = config['num_encoder_symbols']\n",
    "        self.num_decoder_symbols = config['num_decoder_symbols']\n",
    "        \n",
    "        self.use_residual = config['use_residual']\n",
    "        self.attn_input_feeding = config['attn_input_feeding']\n",
    "        self.use_dropout = config['use_dropout']\n",
    "        self.keep_prob = 1.0 - config['dropout_rate']\n",
    "        \n",
    "        self.optimizer = config['optimizer']\n",
    "        self.learning_rate = config['learning_rate']\n",
    "        self.max_gradient_norm = config['max_gradient_norm']\n",
    "        self.global_step = tf.Variable(0, trainable = Flase, name = 'global_step')\n",
    "        self.global_epoch_step = tf.Variable(0,trainable=False, name = \"global_epoch_step\")\n",
    "        self.global_epoch_step_op= tf.assign(self.global_epoch_step,self.global_epoch_step+1)\n",
    "        \n",
    "        self.dtype = tf.float16 if config['use_float16'] else tf.float32\n",
    "        self.keep_prob_placeholder = tf.placeholder(self.dtype, shape=[], name = 'keep_prob')\n",
    "        \n",
    "        self.use_beamsearch_decode = False\n",
    "        if self.mode == 'decode':\n",
    "            self.beam_width = config['beam_width']\n",
    "            self.use_beamsearch_decode = True if self.beam_width > 1 else False\n",
    "            self.max_decode_step = config['max_decode_step']\n",
    "        \n",
    "        self.build_model()\n",
    "        '''\n",
    "    \n",
    "    def build_model(self):\n",
    "            print('building model..')\n",
    "\n",
    "            #building encoder and decoder networks\n",
    "            self.init_placeholders()\n",
    "            '''\n",
    "            self.build_encoder()\n",
    "            self.build_decoder()\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "            '''    \n",
    "    def init_placeholders(self):\n",
    "            #encoder inputs: [batch_size, max_time_steps]\n",
    "            self.encoder_inputs = tf.placeholder(dtype = tf.int32, shape = (None,None), name = 'encoder_inputs')\n",
    "            #encoder_inputs_length: [batch_size]\n",
    "            self.encoder_inputs_length = tf.placeholder(dtype=tf.int32, shape=(None,) , name = 'encoder_inputs_length')\n",
    "            \n",
    "            #get dynamic batch_size\n",
    "            self.batch_size = tf.shape(self.encoder_inputs)[0]\n",
    "            \n",
    "            if(self.mode=='train'):\n",
    "                \n",
    "                #decoder_inputs: [batch_size,max_time_steps]\n",
    "                self.decoder_inputs = tf.placeholder(dtype=tf.int32,shape=(None,None), name ='decoder_inputs')\n",
    "                #decoder_inputs_length: [batch_size]\n",
    "                self.decoder_inputs_length = tf.placeholder(dtype=tf.int32, shape=(None,), name='decoder_inputs_length')\n",
    "                \n",
    "                '''\n",
    "                #No need, already preprocessed\n",
    "                decoder_start_token=tf.ones(shape=[self.batch_size,1], dtype=tf.int32)*data_utils.start_token\n",
    "                \n",
    "                decoder_end_token=tf.ones(shape=[self.batch_size,1], dtype=tf.int32)*data_utils.end_token\n",
    "                '''   \n",
    "    def build_single_cell(self):\n",
    "        cell_type = LSTMCell\n",
    "        cell = cell_type(self.hidden_units)\n",
    "        return cell\n",
    "\n",
    "    def build_encoder_cell (self):\n",
    "        return MultiRNNCell([self.build_single_cell() for i in range(self.depth)])\n",
    "    \n",
    "    def build_encoder(self):\n",
    "        print('Building Encoder..')\n",
    "        with tf.variable_scope('encoder'):\n",
    "            self.encoder_cell = self.build_encoder_cell()\n",
    "            sqrt3 = math.sqrt(3)\n",
    "            initializer = tf.random_uniform_initializer(-sqrt3,sqrt3, dtype=self.dtype)\n",
    "            \n",
    "            #Instantiating embeddings\n",
    "            embedding_variable = tf.Variable(tf.constant(0.0, shape = [vocab_size, embedding_size]),trainable = False, name = 'embedding')\n",
    "                           \n",
    "            embedding_placeholder = tf.placeholder(tf.float32, shape=[vocab_size,embedding_size], name = 'embedding_placeholder' )\n",
    "            self.encoder_embeddings = embedding_variable.assign(embedding_placeholder)\n",
    "            self.encoder_inputs_embedded=tf.nn.embedding_lookup(self.encoder_embeddings,self.encoder_inputs)\n",
    "            \n",
    "            \n",
    "            with tf.Session() as sess:\n",
    "                embed=sess.run(self.encoder_inputs_embedded, feed_dict={embedding_placeholder:emb ,self.encoder_inputs:eInput })\n",
    "                print(embed[0])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model..\n",
      "Building Encoder..\n",
      "[[-1.4168e-01  4.1108e-01 -3.1227e-01  1.6633e-01  2.6124e-01  4.5708e-01\n",
      "  -1.2001e+00  1.4923e-02 -2.2779e-01 -1.6937e-01  3.4633e-01 -1.2419e-01\n",
      "  -6.5711e-01  2.9226e-01  6.2407e-01 -5.7916e-01 -3.3947e-01 -2.2046e-01\n",
      "  -1.4832e+00  2.8958e-01  8.1396e-02 -2.1696e-01  5.6613e-03 -5.4199e-02\n",
      "   9.8504e-02 -1.5874e+00 -2.2867e-01 -6.2957e-01 -3.9542e-01 -8.0841e-02\n",
      "   3.5949e+00 -1.6872e-01 -3.9024e-01  2.6912e-02  5.2646e-01 -2.2844e-02\n",
      "   6.3289e-01  6.2702e-01 -2.2171e-01 -4.5045e-01 -1.4998e-01 -2.7723e-01\n",
      "  -4.6658e-01 -4.4268e-01 -4.3691e-01  3.8455e-01  1.3690e-01 -2.5424e-01\n",
      "   1.7821e-02 -1.4890e-01]\n",
      " [ 7.0853e-01  5.7088e-01 -4.7160e-01  1.8048e-01  5.4449e-01  7.2603e-01\n",
      "   1.8157e-01 -5.2393e-01  1.0381e-01 -1.7566e-01  7.8852e-02 -3.6216e-01\n",
      "  -1.1829e-01 -8.3336e-01  1.1917e-01 -1.6605e-01  6.1555e-02 -1.2719e-02\n",
      "  -5.6623e-01  1.3616e-02  2.2851e-01 -1.4396e-01 -6.7549e-02 -3.8157e-01\n",
      "  -2.3698e-01 -1.7037e+00 -8.6692e-01 -2.6704e-01 -2.5890e-01  1.7670e-01\n",
      "   3.8676e+00 -1.6130e-01 -1.3273e-01 -6.8881e-01  1.8444e-01  5.2464e-03\n",
      "  -3.3874e-01 -7.8956e-02  2.4185e-01  3.6576e-01 -3.4727e-01  2.8483e-01\n",
      "   7.5693e-02 -6.2178e-02 -3.8988e-01  2.2902e-01 -2.1617e-01 -2.2562e-01\n",
      "  -9.3918e-02 -8.0375e-01]\n",
      " [ 1.9253e-01  1.0006e-01  6.3798e-02 -8.7664e-02  5.2217e-01  3.9105e-01\n",
      "  -4.1975e-01 -4.5671e-01 -3.4053e-01 -1.1175e-01  1.4754e-02  3.1734e-01\n",
      "  -5.0853e-01 -1.1560e-01  7.4303e-01  9.7618e-02  3.4407e-01 -1.2130e-01\n",
      "  -1.6938e-01 -8.4088e-01 -1.1231e-01  4.0602e-01  7.6801e-01  9.1138e-02\n",
      "   1.0782e-01 -1.2673e+00 -5.7709e-01 -3.6208e-01  3.4824e-01 -7.5458e-01\n",
      "   4.0426e+00  9.4967e-01 -2.2668e-01 -3.5777e-01  3.4130e-01  1.3072e-01\n",
      "   2.3045e-01 -3.6997e-02 -2.5889e-01  1.2977e-01 -3.9031e-01 -4.9607e-02\n",
      "   4.5766e-01  5.6782e-01 -4.6165e-01  4.1933e-01 -5.4920e-01  8.1191e-02\n",
      "  -3.0485e-01 -3.0513e-01]\n",
      " [ 1.1891e-01  1.5255e-01 -8.2073e-02 -7.4144e-01  7.5917e-01 -4.8328e-01\n",
      "  -3.1009e-01  5.1476e-01 -9.8708e-01  6.1757e-04 -1.5043e-01  8.3770e-01\n",
      "  -1.0797e+00 -5.1460e-01  1.3188e+00  6.2007e-01  1.3779e-01  4.7108e-01\n",
      "  -7.2874e-02 -7.2675e-01 -7.4116e-01  7.5263e-01  8.8180e-01  2.9561e-01\n",
      "   1.3548e+00 -2.5701e+00 -1.3523e+00  4.5880e-01  1.0068e+00 -1.1856e+00\n",
      "   3.4737e+00  7.7898e-01 -7.2929e-01  2.5102e-01 -2.6156e-01 -3.4684e-01\n",
      "   5.5841e-01  7.5098e-01  4.9830e-01 -2.6823e-01 -2.7443e-03 -1.8298e-02\n",
      "  -2.8096e-01  5.5318e-01  3.7706e-02  1.8555e-01 -1.5025e-01 -5.7512e-01\n",
      "  -2.6671e-01  9.2121e-01]\n",
      " [ 7.6190e-01 -2.9773e-01  5.1396e-01 -1.3303e-01  2.4156e-01  6.6799e-02\n",
      "  -5.4084e-01  2.0710e-01 -2.8225e-01 -1.1638e-01  2.1666e-01  5.4908e-01\n",
      "  -3.6744e-01 -1.0543e-01  8.1567e-01  1.1743e+00  5.6055e-01 -3.3450e-01\n",
      "   9.9767e-02 -8.7465e-01  1.2229e-01 -1.8532e-01  8.6783e-02 -3.6343e-01\n",
      "   8.0020e-03 -2.2268e+00 -2.0079e-01 -1.0313e-01  2.4318e-01 -3.9819e-01\n",
      "   3.7136e+00  5.9088e-01 -1.1013e+00 -2.5292e-01  5.7067e-03 -6.0475e-01\n",
      "   3.5965e-01 -5.9581e-02 -2.9059e-02 -3.9890e-01 -5.2631e-01  1.2436e-01\n",
      "   1.3609e-01  1.2699e-01 -2.3032e-01 -4.4567e-02 -6.5450e-01  4.3088e-01\n",
      "  -2.2768e-01  4.0260e-01]\n",
      " [ 3.6808e-01  2.0834e-01 -2.2319e-01  4.6283e-02  2.0098e-01  2.7515e-01\n",
      "  -7.7127e-01 -7.6804e-01 -3.4861e-01  5.0620e-01 -2.4401e-01  7.1775e-01\n",
      "  -3.3348e-01  3.7554e-01  4.4756e-01  3.6698e-01  4.3533e-01  4.7570e-01\n",
      "  -5.6113e-02 -9.3531e-01 -2.7591e-01  3.1610e-01  2.2116e-01  3.6304e-01\n",
      "   1.0757e-01 -1.7638e+00 -1.2624e+00  3.0284e-01  5.6286e-01 -1.0214e+00\n",
      "   3.2353e+00  4.8483e-01  2.7953e-02  3.6082e-02 -7.8554e-02  1.8761e-01\n",
      "  -5.2573e-01  3.7200e-02  2.7579e-01 -7.7360e-02 -2.7955e-01  7.9752e-01\n",
      "   1.6028e-03  4.5479e-01  8.8382e-01  4.3893e-01 -1.9263e-01 -6.7236e-01\n",
      "  -3.9709e-01  2.5183e-01]\n",
      " [ 6.8047e-01 -3.9263e-02  3.0186e-01 -1.7792e-01  4.2962e-01  3.2246e-02\n",
      "  -4.1376e-01  1.3228e-01 -2.9847e-01 -8.5253e-02  1.7118e-01  2.2419e-01\n",
      "  -1.0046e-01 -4.3653e-01  3.3418e-01  6.7846e-01  5.7204e-02 -3.4448e-01\n",
      "  -4.2785e-01 -4.3275e-01  5.5963e-01  1.0032e-01  1.8677e-01 -2.6854e-01\n",
      "   3.7334e-02 -2.0932e+00  2.2171e-01 -3.9868e-01  2.0912e-01 -5.5725e-01\n",
      "   3.8826e+00  4.7466e-01 -9.5658e-01 -3.7788e-01  2.0869e-01 -3.2752e-01\n",
      "   1.2751e-01  8.8359e-02  1.6351e-01 -2.1634e-01 -9.4375e-02  1.8324e-02\n",
      "   2.1048e-01 -3.0880e-02 -1.9722e-01  8.2279e-02 -9.4340e-02 -7.3297e-02\n",
      "  -6.4699e-02 -2.6044e-01]\n",
      " [-8.0576e-02  5.3089e-01  9.0476e-02 -7.5803e-01  1.0413e+00 -1.1414e+00\n",
      "  -3.2336e-01  6.6704e-01 -1.6739e-01  2.7511e-01 -3.7938e-01  1.1108e+00\n",
      "   6.2335e-02 -1.8604e-01  6.2351e-01 -3.3423e-01  1.5737e-01  3.5646e-02\n",
      "   6.0456e-01 -4.4281e-01 -3.9813e-01  8.9021e-01  3.8328e-01 -2.1072e-01\n",
      "   1.3334e+00 -1.2462e+00 -7.8527e-01 -4.9328e-04  2.4480e-02 -1.2480e+00\n",
      "   1.4301e+00  1.4415e+00 -6.5934e-01  4.6623e-01 -7.0287e-01 -1.3547e-01\n",
      "   5.9801e-01 -2.7746e-01  5.1279e-03 -4.7076e-01  5.1226e-01  2.9749e-02\n",
      "  -4.5041e-01 -4.0528e-01  1.0441e-01  4.8741e-01 -8.1725e-01  1.8100e-02\n",
      "  -9.2554e-02  4.5772e-01]\n",
      " [-1.0919e-03  3.3324e-01  3.5743e-01 -5.4041e-01  8.2032e-01 -4.9391e-01\n",
      "  -3.2588e-01  1.9972e-03 -2.3829e-01  3.5554e-01 -6.0655e-01  9.8932e-01\n",
      "  -2.1786e-01  1.1236e-01  1.1494e+00  7.3284e-01  5.1182e-01  2.9287e-01\n",
      "   2.8388e-01 -1.3590e+00 -3.7951e-01  5.0943e-01  7.0710e-01  6.2941e-01\n",
      "   1.0534e+00 -2.1756e+00 -1.3204e+00  4.0001e-01  1.5741e+00 -1.6600e+00\n",
      "   3.7721e+00  8.6949e-01 -8.0439e-01  1.8390e-01 -3.4332e-01  1.0714e-02\n",
      "   2.3969e-01  6.6748e-02  7.0117e-01 -7.3702e-01  2.0877e-01  1.1564e-01\n",
      "  -1.5190e-01  8.5908e-01  2.2620e-01  1.6519e-01  3.6309e-01 -4.5697e-01\n",
      "  -4.8969e-02  1.1316e+00]\n",
      " [ 1.5272e-01  3.6181e-01 -2.2168e-01  6.6051e-02  1.3029e-01  3.7075e-01\n",
      "  -7.5874e-01 -4.4722e-01  2.2563e-01  1.0208e-01  5.4225e-02  1.3494e-01\n",
      "  -4.3052e-01 -2.1340e-01  5.6139e-01 -2.1445e-01  7.7974e-02  1.0137e-01\n",
      "  -5.1306e-01 -4.0295e-01  4.0639e-01  2.3309e-01  2.0696e-01 -1.2668e-01\n",
      "  -5.0634e-01 -1.7131e+00  7.7183e-02 -3.9138e-01 -1.0594e-01 -2.3743e-01\n",
      "   3.9552e+00  6.6596e-01 -6.1841e-01 -3.2680e-01  3.7021e-01  2.5764e-01\n",
      "   3.8977e-01  2.7121e-01  4.3024e-02 -3.4322e-01  2.0339e-02  2.1420e-01\n",
      "   4.4097e-02  1.4003e-01 -2.0079e-01  7.4794e-02 -3.6076e-01  4.3382e-01\n",
      "  -8.4617e-02  1.2140e-01]\n",
      " [ 9.7055e-02  2.1087e-01  1.7822e-01 -3.3152e-01  5.8994e-01  3.9979e-01\n",
      "  -5.1005e-01  3.6011e-01  1.9315e-01  5.6127e-01 -2.5413e-01  2.8233e-02\n",
      "   7.1628e-02 -2.1901e-01  1.4005e-01 -2.3146e-01  1.3386e-01 -6.1865e-01\n",
      "   2.8993e-02 -5.5777e-01  3.2942e-02  2.1639e-01  1.2896e-01 -3.2385e-01\n",
      "   3.5642e-02 -1.5103e+00  1.4495e-01 -1.7384e-01  3.0914e-01 -4.6946e-01\n",
      "   3.1608e+00  8.2007e-01 -3.7222e-01 -2.2913e-01  1.0672e-01 -8.9373e-02\n",
      "   1.4235e-01  2.3459e-01 -2.9017e-01 -4.8766e-01  1.8618e-01  1.3497e-02\n",
      "  -1.1468e-01  4.6142e-01 -3.0235e-01 -8.8673e-02 -4.4375e-01  4.8949e-01\n",
      "   2.1815e-02  5.7208e-02]\n",
      " [-1.4525e-01  3.1265e-01  1.5184e-01 -6.3708e-01  6.3553e-01 -5.0295e-01\n",
      "  -2.3214e-01  5.2892e-01 -5.8629e-01  5.3935e-01 -3.0550e-01  1.0357e+00\n",
      "  -7.7989e-01 -1.9387e-01  1.2215e+00  2.4521e-01  2.6144e-01  2.2439e-01\n",
      "   1.5584e-01 -7.9146e-01 -6.5262e-01  1.3211e+00  7.6618e-01  3.8234e-01\n",
      "   1.4453e+00 -2.2643e+00 -1.1505e+00  5.0373e-01  1.2651e+00 -1.5903e+00\n",
      "   3.0518e+00  8.4118e-01 -6.9543e-01  2.9985e-01 -4.9151e-01 -2.2312e-01\n",
      "   5.9528e-01 -7.6347e-02  5.2358e-01 -5.0134e-01  2.2483e-01  1.5460e-02\n",
      "  -8.8005e-02  2.1282e-01  2.8545e-01 -1.5976e-01 -1.6777e-01 -5.0895e-01\n",
      "   1.4322e-01  1.0118e+00]\n",
      " [ 3.1712e-01  4.1507e-01 -9.8277e-02 -1.2133e-02  9.7186e-01 -5.5760e-01\n",
      "  -4.4919e-01  5.7340e-01  3.5215e-01  4.2165e-01 -2.3140e-01  4.1324e-01\n",
      "  -3.0235e-01 -2.6445e-01  1.8005e-01  2.6517e-01  1.1176e+00 -4.1335e-01\n",
      "   1.5681e-01 -6.3890e-01  2.9914e-01  2.8229e-01 -5.3865e-01 -1.7303e-01\n",
      "   7.4050e-01 -1.4578e+00 -3.2100e-01 -7.6700e-01  4.0827e-01 -5.6598e-01\n",
      "   2.8828e+00  1.2693e+00 -8.5054e-01 -9.0125e-01 -1.8945e-01 -1.1787e-01\n",
      "  -4.2502e-01  4.6328e-01 -3.6772e-01 -8.7853e-01 -2.3246e-01 -4.6698e-01\n",
      "  -1.5860e-01  2.1720e-01 -3.3028e-01  1.1534e-01  1.0061e-01  4.3399e-01\n",
      "   6.7090e-02  1.6457e-01]\n",
      " [ 6.8047e-01 -3.9263e-02  3.0186e-01 -1.7792e-01  4.2962e-01  3.2246e-02\n",
      "  -4.1376e-01  1.3228e-01 -2.9847e-01 -8.5253e-02  1.7118e-01  2.2419e-01\n",
      "  -1.0046e-01 -4.3653e-01  3.3418e-01  6.7846e-01  5.7204e-02 -3.4448e-01\n",
      "  -4.2785e-01 -4.3275e-01  5.5963e-01  1.0032e-01  1.8677e-01 -2.6854e-01\n",
      "   3.7334e-02 -2.0932e+00  2.2171e-01 -3.9868e-01  2.0912e-01 -5.5725e-01\n",
      "   3.8826e+00  4.7466e-01 -9.5658e-01 -3.7788e-01  2.0869e-01 -3.2752e-01\n",
      "   1.2751e-01  8.8359e-02  1.6351e-01 -2.1634e-01 -9.4375e-02  1.8324e-02\n",
      "   2.1048e-01 -3.0880e-02 -1.9722e-01  8.2279e-02 -9.4340e-02 -7.3297e-02\n",
      "  -6.4699e-02 -2.6044e-01]\n",
      " [-1.0833e-01 -3.9089e-01 -7.9456e-02 -1.2089e-01 -4.6821e-01  4.4296e-01\n",
      "  -1.2347e-01 -8.6624e-01  1.1788e-01  5.6956e-01  1.4304e-01  3.8266e-01\n",
      "   3.3600e-01  2.6793e-01  9.9842e-02  5.4880e-01 -6.7791e-02 -2.2731e-01\n",
      "   8.0081e-01 -8.9202e-01  8.4459e-01 -5.4385e-01 -6.2321e-01  1.8469e-01\n",
      "   5.6410e-02 -1.2114e+00  3.3063e-02 -7.6490e-01  3.1885e-02 -2.7129e-01\n",
      "   2.1749e+00  5.9019e-01 -1.3210e+00 -3.8308e-01  2.2481e-01 -1.7429e-01\n",
      "   2.5433e-01  1.3233e-01 -8.9258e-01 -3.5532e-01 -5.0447e-02  1.2102e-02\n",
      "   4.4980e-02 -1.3272e-02  1.8377e-01  3.2482e-01  3.1909e-01  3.6458e-01\n",
      "   1.5785e-01  5.8252e-01]\n",
      " [-2.4606e-01 -3.6208e-01  1.6298e-01 -1.0539e+00  1.0150e+00 -1.2986e-01\n",
      "   2.9943e-02  7.0045e-01 -5.1904e-01  3.7297e-01 -1.7724e-01  5.8895e-01\n",
      "  -8.6737e-01 -3.9516e-02  9.4961e-01  4.2915e-01  6.7331e-01  2.0087e-01\n",
      "   3.7476e-01 -8.8860e-01  3.6479e-03  1.1954e+00  7.0964e-01  3.9676e-01\n",
      "   1.5242e+00 -1.5306e+00 -6.2682e-01  1.4013e-01  1.0916e+00 -1.1345e+00\n",
      "   2.2712e+00  9.5910e-01 -4.0827e-01 -2.4700e-01 -5.4859e-01 -1.4245e-02\n",
      "   3.5309e-01  6.7128e-01  1.8092e-01 -6.5520e-01  5.8029e-02 -6.4046e-01\n",
      "  -3.0244e-02  6.9860e-01  1.9883e-01 -1.6348e-01 -1.4961e-01 -4.0892e-01\n",
      "   2.4814e-01  5.2553e-01]\n",
      " [ 1.1891e-01  1.5255e-01 -8.2073e-02 -7.4144e-01  7.5917e-01 -4.8328e-01\n",
      "  -3.1009e-01  5.1476e-01 -9.8708e-01  6.1757e-04 -1.5043e-01  8.3770e-01\n",
      "  -1.0797e+00 -5.1460e-01  1.3188e+00  6.2007e-01  1.3779e-01  4.7108e-01\n",
      "  -7.2874e-02 -7.2675e-01 -7.4116e-01  7.5263e-01  8.8180e-01  2.9561e-01\n",
      "   1.3548e+00 -2.5701e+00 -1.3523e+00  4.5880e-01  1.0068e+00 -1.1856e+00\n",
      "   3.4737e+00  7.7898e-01 -7.2929e-01  2.5102e-01 -2.6156e-01 -3.4684e-01\n",
      "   5.5841e-01  7.5098e-01  4.9830e-01 -2.6823e-01 -2.7443e-03 -1.8298e-02\n",
      "  -2.8096e-01  5.5318e-01  3.7706e-02  1.8555e-01 -1.5025e-01 -5.7512e-01\n",
      "  -2.6671e-01  9.2121e-01]\n",
      " [ 3.4664e-01  3.9805e-01  4.8970e-01 -5.1421e-01  5.4574e-01 -1.2005e+00\n",
      "   3.2107e-01  7.4004e-01 -1.4979e+00 -1.9651e-01 -1.2631e-01 -3.7703e-01\n",
      "  -6.2569e-01  3.8792e-02  1.0579e+00  7.7199e-01 -1.8589e-01  1.3032e+00\n",
      "  -7.2128e-01  4.0231e-01  6.6442e-02  1.2315e+00  9.3956e-01  1.3903e+00\n",
      "   1.5334e+00 -1.4730e+00 -3.4997e-01  3.1562e-01  9.0691e-01  4.5498e-01\n",
      "   2.5481e+00  1.6410e-01 -6.0700e-01  2.7061e-01 -7.9072e-01 -1.1460e+00\n",
      "   9.1795e-01 -1.1797e-01  2.3526e-01 -1.2659e-01  6.6527e-01 -9.1816e-01\n",
      "   1.0048e-01  7.0457e-01 -2.1777e-01  5.2479e-01 -5.4452e-01  8.6576e-02\n",
      "   3.4037e-01  1.3588e+00]\n",
      " [ 3.1414e-01 -1.1675e+00  1.0037e-01  8.4619e-01  7.5376e-01 -1.9291e-01\n",
      "   7.3314e-01 -6.7713e-01 -6.8135e-01  8.1858e-01  4.0700e-01  1.7735e+00\n",
      "  -9.0390e-01  9.0395e-01 -1.1532e-01  6.9961e-02  1.8396e-01  1.1895e+00\n",
      "  -1.4116e-01  1.0850e+00  1.1117e-01  5.5776e-01  4.8181e-01  1.0482e-01\n",
      "   5.0381e-01 -1.9772e-01  1.3368e+00 -3.0328e-01 -1.0170e+00 -1.6690e-01\n",
      "  -4.6027e-01 -5.2147e-01  1.2740e+00  4.5508e-01 -1.4969e-01  7.6604e-02\n",
      "  -1.5590e+00  1.4002e-01  2.5100e-01  3.2542e-01 -7.0485e-01  1.3335e+00\n",
      "  -4.5069e-01  4.9852e-01 -9.2195e-01 -3.9966e-01  6.7322e-01 -1.9203e-01\n",
      "  -4.2339e-01  1.1129e-03]\n",
      " [ 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#Testing Seq2Seq\n",
    "config ={}\n",
    "\n",
    "obj = Seq2SeqModel('train',1,150,False)\n",
    "obj.build_model()\n",
    "obj.build_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
