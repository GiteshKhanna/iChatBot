{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.ops.rnn_cell import GRUCell\n",
    "from tensorflow.python.ops.rnn_cell import LSTMCell\n",
    "from tensorflow.python.ops.rnn_cell import MultiRNNCell\n",
    "from tensorflow.python.ops.rnn_cell import DropoutWrapper, ResidualWrapper\n",
    "\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.util import nest\n",
    "\n",
    "from tensorflow.contrib.seq2seq.python.ops import attention_wrapper\n",
    "from tensorflow.contrib.seq2seq.python.ops import beam_search_decoder\n",
    "\n",
    "from preprocess import *\n",
    "from loading_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetter\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding parameters\n",
    "embedding_size = 50\n",
    "\n",
    "#data parameters\n",
    "eMax_allowed_length = 20\n",
    "dMax_allowed_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching data\n",
    "#default directory: 'data/data_10.csv'\n",
    "X,Y= read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching glove vectors\n",
    "#default directory: \"./glove.6B.50d.txt\"\n",
    "embedding_size = 50\n",
    "wi,iw,wv = read_glove_vecs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding extra tokens to glove dictionary\n",
    "go_index,eos_index,unk_index = add_extra_to_dict(wi,iw,wv,embedding_size)\n",
    "emb = map_dict_to_list(iw,wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data\n",
    "#Mapping each word in a sentence to its glove index\n",
    "eInput,eLengths = fit_encoder_text(data= X[1:],word_to_index = wi,max_allowed_seq_length = eMax_allowed_length)\n",
    "dInput,dOutput,dLengths = fit_decoder_text(data= Y[1:],word_to_index = wi,max_allowed_seq_length = dMax_allowed_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel():\n",
    "    def __init__(self,config,mode):\n",
    "        assert mode.lower() in ['train','decode']\n",
    "        \n",
    "        self.mode = mode.lower()\n",
    "        \n",
    "        #num_encoder_symbols and num_decoder_symbols\n",
    "        self.encoder_vocab_size = 400003\n",
    "        self.decoder_vocab_size = 400003\n",
    "\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        \n",
    "        self.cell_type = config['cell_type']\n",
    "        self.hidden_units = config['hidden_units']\n",
    "        self.depth = config['depth']\n",
    "        self.attention_type = config['attention_type']\n",
    "        self.embedding_size = config['embedding_size']\n",
    "        \n",
    "        self.use_residual = config['use_residual']\n",
    "        self.attn_input_feeding = config['attn_input_feeding']\n",
    "        self.use_dropout = config['use_dropout']\n",
    "        self.keep_prob = 1.0 - config['dropout_rate']\n",
    "        \n",
    "        self.optimizer = config['optimizer']\n",
    "        self.learning_rate = config['learning_rate']\n",
    "        self.max_gradient_norm = config['max_gradient_norm']\n",
    "        self.global_step = tf.Variable(0, trainable = False, name = 'global_step')\n",
    "        self.global_epoch_step = tf.Variable(0,trainable=False, name = \"global_epoch_step\")\n",
    "        self.global_epoch_step_op= tf.assign(self.global_epoch_step,self.global_epoch_step+1)\n",
    "        \n",
    "        self.dtype = tf.float16 if config['use_float16'] else tf.float32\n",
    "        self.keep_prob_placeholder = tf.placeholder(self.dtype, shape=[], name = 'keep_prob')\n",
    "        \n",
    "        self.use_beamsearch_decode = False\n",
    "        if self.mode == 'decode':\n",
    "            self.beam_width = config['beam_width']\n",
    "            self.use_beamsearch_decode = True if self.beam_width > 1 else False\n",
    "            self.max_decode_step = config['max_decode_step']\n",
    "        \n",
    "        self.build_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "            print('building model..')\n",
    "\n",
    "            #building encoder and decoder networks\n",
    "            self.init_placeholders()\n",
    "            '''\n",
    "            self.build_encoder()\n",
    "            self.build_decoder()\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "            '''    \n",
    "    def init_placeholders(self):\n",
    "            #encoder inputs: [batch_size, max_time_steps]\n",
    "            self.encoder_inputs = tf.placeholder(dtype = tf.int32, shape = (None,None), name = 'encoder_inputs')\n",
    "            #encoder_inputs_length: [batch_size]\n",
    "            self.encoder_inputs_length = tf.placeholder(dtype=tf.int32, shape=(None,) , name = 'encoder_inputs_length')\n",
    "            \n",
    "            #get dynamic batch_size\n",
    "            self.batch_size = tf.shape(self.encoder_inputs)[0]\n",
    "            \n",
    "            if(self.mode=='train'):\n",
    "                \n",
    "                #decoder_inputs: [batch_size,max_time_steps]\n",
    "                self.decoder_inputs = tf.placeholder(dtype=tf.int32,shape=(None,None), name ='decoder_inputs')\n",
    "                #decoder_inputs_length: [batch_size]\n",
    "                self.decoder_inputs_length = tf.placeholder(dtype=tf.int32, shape=(None,), name='decoder_inputs_length')\n",
    "                \n",
    "                self.decoder_targets = tf.placeholder(dtype=tf.int32,shape=(None,None), name ='decoder_targets')\n",
    "                \n",
    "                '''\n",
    "                #No need, already preprocessed\n",
    "                decoder_start_token=tf.ones(shape=[self.batch_size,1], dtype=tf.int32)*data_utils.start_token\n",
    "                \n",
    "                decoder_end_token=tf.ones(shape=[self.batch_size,1], dtype=tf.int32)*data_utils.end_token\n",
    "                '''\n",
    "                \n",
    "    def build_single_cell(self):\n",
    "        cell_type = LSTMCell\n",
    "        if(self.cell_type.lower() == 'gru'):\n",
    "            cell_type = GRUCell\n",
    "        cell = cell_type(self.hidden_units)\n",
    "        \n",
    "        if self.use_dropout:\n",
    "            cell = DropoutWrapper(cell,dtype=self.dtype,\n",
    "                                 output_keep_prob = self.keep_prob_placeholder)\n",
    "            \n",
    "        if self.use_residual:\n",
    "            cell = ResidualWrapper(cell)\n",
    "            \n",
    "        return cell\n",
    "\n",
    "    def build_encoder_cell (self):\n",
    "        return MultiRNNCell([self.build_single_cell() for i in range(self.depth)])\n",
    "    \n",
    "    def build_decoder_cell(self):\n",
    "        encoder_outputs = self.encoder_outputs\n",
    "        encoder_last_state = self.encoder_last_state\n",
    "        encoder_inputs_length = self.encoder_inputs_length\n",
    "        \n",
    "        if self.use_beamsearch_decode:\n",
    "            print('using beamsearch..')\n",
    "            encoder_outputs = seq2seq.tile_batch(self.encoder_outputs,\n",
    "                                                 multiplier=self.beam_width)\n",
    "            encoder_last_state = nest.map_structure( lambda s: seq2seq.tile_batch(s,self.beam_width),\n",
    "                                                   self.encoder_last_state)\n",
    "            encoder_inputs_length = seq2seq.tile_batch(self.encoder_inputs_length,\n",
    "                                                       multiplier=self.beam_width)\n",
    "            #Building attention mechanism: Default Bahdanau\n",
    "            #'Bahdanau' style attention\n",
    "        self.attention_mechanism = attention_wrapper.BahdanauAttention(\n",
    "        num_units=self.hidden_units, memory=encoder_outputs,\n",
    "        memory_sequence_length=encoder_inputs_length,\n",
    "        name='BahdanauAttention')\n",
    "        \n",
    "        # 'Luong' style attention:\n",
    "        if self.attention_type.lower() == 'luong':\n",
    "            self.attention_mechanism = attention_wrapper.LuongAttention(\n",
    "            num_units = self.hidden_units, memory=encoder_outputs,\n",
    "            memory_sequence_length=encoder_inputs_length,\n",
    "            name='LuongAttention')\n",
    "                \n",
    "        #Building decoder_cell\n",
    "        self.decoder_cell_list = [self.build_single_cell() for i in range(self.depth)]\n",
    "        decoder_initial_state = encoder_last_state\n",
    "        \n",
    "        def attn_decoder_input_fn(inputs,attention):\n",
    "            if not self.attn_input_feeding:\n",
    "                return inputs\n",
    "            \n",
    "            _input_layer = Dense(self.hidden_units,dtype = self.dtype,\n",
    "                                name = 'attn_input_feeding')\n",
    "            return _input_layer(array_ops.concat([inputs,attention],-1))\n",
    "        \n",
    "        self.decoder_cell_list[-1] = attention_wrapper.AttentionWrapper(\n",
    "        cell = self.decoder_cell_list[-1],\n",
    "        attention_mechanism=self.attention_mechanism,\n",
    "        attention_layer_size=self.hidden_units,\n",
    "        cell_input_fn=attn_decoder_input_fn,\n",
    "        initial_cell_state=encoder_last_state[-1],\n",
    "        alignment_history=False,\n",
    "        name='Attention Wrapper')\n",
    "        \n",
    "        # Encoder last state must be compatible with AttentionWrapper\n",
    "        #Attentionwrapper.zero_state is used for the purpose\n",
    "        \n",
    "        batch_size = self.batch_size if not self.use_beamsearch_decode else self.batch_size*self.beam_width\n",
    "        initial_state = [state for state in encoder_last_state]\n",
    "        \n",
    "        initial_state[-1]= self.decoder_cell_list[-1].zero_state(\n",
    "        batch_size = batch_size, dtype=self.dtype)\n",
    "        decoder_initial_state = tuple(initial_state)\n",
    "        \n",
    "        return MultiRNNCell(self.decoder_cell_list),decoder_initial_state\n",
    "        \n",
    "    \n",
    "    def init_optimizer(self):\n",
    "        print(\"Setting optimizer..\")\n",
    "        #Gradients and SGD update operaton for training the model\n",
    "        trainable_params = tf.trainable_variables()\n",
    "        if self.optimizer.lower() == 'adadelta':\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\n",
    "        elif self.optmizer.lower() == 'adam':\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\n",
    "        elif self.optimizer.lower() == 'rmsprop':\n",
    "            self.opt = tf.train.RMSPropOptimizer(learning_rate = self.learning_rate)\n",
    "        else:\n",
    "            self.opt = tf.train.GradientDescentOptimizer(learning_rate = self.learning_rate)\n",
    "            \n",
    "        \n",
    "        #Compute gradients of loss w.r.t all trainable variables\n",
    "        gradients = tf.gradients(self.loss,trainable_params)\n",
    "        \n",
    "        #Clip gradients of loss w.r.t all trainable variables\n",
    "        clip_gradients,_ = tf.clip_by_global_norm(gradients,self.max_gradient_norm)\n",
    "        \n",
    "        #Update the model\n",
    "        self.updates = self.opt.apply_gradients(zip(clip_gradients,trainable_params),\n",
    "                                                global_step = self.global_step)\n",
    "        \n",
    "    def save(self,sess,path,var_list=None,global_step=None):\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        \n",
    "        save_path = saver.save(sess,save_path=path,global_step=step)\n",
    "        print('model saved at ',save_path)\n",
    "        \n",
    "    def restore(self,sess,path,var_list=None):\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.restore(sess, save_path = path)\n",
    "        print('model restored from ',path)\n",
    "    \n",
    "    def build_encoder(self):\n",
    "        print('Building Encoder..')\n",
    "        with tf.variable_scope('encoder'):\n",
    "            self.encoder_cell = self.build_encoder_cell()\n",
    "            \n",
    "            #Instantiating pretrained embeddings\n",
    "            embedding_variable = tf.Variable(tf.constant(0.0, shape = [self.encoder_vocab_size, embedding_size]),trainable = False, name = 'embedding')\n",
    "                           \n",
    "            self.encoder_embedding_placeholder = tf.placeholder(tf.float32, shape=[self.encoder_vocab_size,embedding_size], name = 'embedding_placeholder' )\n",
    "            self.encoder_embeddings = embedding_variable.assign(self.encoder_embedding_placeholder)\n",
    "            self.encoder_inputs_embedded=tf.nn.embedding_lookup(self.encoder_embeddings,self.encoder_inputs)\n",
    "            \n",
    "    \n",
    "            #instantiating dense layer\n",
    "            input_layer = Dense(self.hidden_units, dtype = self.dtype, name = 'input_projection')\n",
    "            #passing the embedding through dense layer\n",
    "            self.encoder_inputs_embedded = input_layer(self.encoder_inputs_embedded)\n",
    "            \n",
    "            #Encode input sequences into context vectors\n",
    "            #encoder_outputs: [batch_size, max_time_step, cell_output_size]\n",
    "            #encoder_state: [batch_size,cell_output_size]\n",
    "            self.encoder_outputs, self.encoder_last_state = tf.nn.dynamic_rnn(cell = self.encoder_cell,\n",
    "                                                                               inputs=self.encoder_inputs_embedded,\n",
    "                                                                               sequence_length=self.encoder_inputs_length,\n",
    "                                                                               dtype=self.dtype,\n",
    "                                                                               time_major=False)\n",
    "            \n",
    "            '''\n",
    "            init = tf.global_variables_initializer()\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(init)\n",
    "                enc_outputs,enc_laststate=sess.run([self.encoder_outputs,self.encoder_last_state], \n",
    "                                                   feed_dict={self.encoder_embedding_placeholder:emb ,\n",
    "                                                              self.encoder_inputs:eInput, \n",
    "                                                              self.encoder_inputs_length: eLengths })\n",
    "                print('encoder Outputs:',enc_outputs.shape)\n",
    "                print(enc_outputs)\n",
    "                print()\n",
    "                print('Encoder last state:',len(enc_laststate))\n",
    "                print(enc_laststate)\n",
    "            '''\n",
    "        \n",
    "\n",
    "    def build_decoder(self):\n",
    "        print('Building decoder and attention...')\n",
    "        with tf.variable_scope('decoder'):\n",
    "                \n",
    "            #Recheck this code\n",
    "            self.decoder_cell,self.decoder_initial_state = self.build_decoder_cell()\n",
    "            \n",
    "            #Instantiating pretrained embeddings\n",
    "            embedding_variable = tf.Variable(tf.constant(0.0, shape = [self.decoder_vocab_size, embedding_size]),trainable = False, name = 'embedding')\n",
    "\n",
    "            self.decoder_embedding_placeholder = tf.placeholder(tf.float32, shape=[self.decoder_vocab_size,embedding_size], name = 'embedding_placeholder' )\n",
    "            self.decoder_embeddings = embedding_variable.assign(self.decoder_embedding_placeholder)\n",
    "            self.decoder_inputs_embedded=tf.nn.embedding_lookup(self.decoder_embeddings,self.encoder_inputs)\n",
    "                \n",
    "            #instantiating dense layer --> DOUBT\n",
    "            input_layer = Dense(self.hidden_units, dtype = self.dtype, name = 'input_projection')\n",
    "                \n",
    "            #Output projection layer to convert cell outputs to logits --> DOUBT\n",
    "            output_layer = Dense(self.decoder_vocab_size,\"output_projection\")\n",
    "                \n",
    "            if self.mode == 'train':\n",
    "                #decoder_inputs_embedded: [batch_size,max_time_step,embedding_size]\n",
    "                self.decoder_inputs_embededded = tf.nn.embedding_lookup(self.decoder_embeddings,\n",
    "                                                                           self.decoder_inputs_train)\n",
    "                    \n",
    "                #Embedded inputs going through projection layer\n",
    "                self.decoder_inputs_embedded=input_layer(self.decoder_inputs_embedded)\n",
    "                    \n",
    "                #Helper to feed inputs for training: read inputs from dense ground truth vectors\n",
    "                training_helper = seq2seq.TrainingHelper(inputs = self.decoder_inputs_embedded,\n",
    "                                                            sequence_length=self.decoder_inputs_length,\n",
    "                                                            time_major=False,\n",
    "                                                            name='training_helper')\n",
    "                training_decoder = seq2seq.BasicDecoder(cell=self.decoder_cell,\n",
    "                                                           helper = training_helper,\n",
    "                                                           initial_state = self.decoder_initial_state,\n",
    "                                                           output_layer = outputl_layer)\n",
    "                    \n",
    "                #Maximum decoder time_steps in current batch\n",
    "                max_decoder_length = tf.reduce_max(self.decoder_inputs_length)\n",
    "                    \n",
    "                # decoder_outputs_train: BasicDecoderOutput\n",
    "                #                        namedtuple(rnn_outputs, sample_id)\n",
    "                # decoder_outputs_train.rnn_output: [batch_size, max_time_step + 1, num_decoder_symbols] if output_time_major=False\n",
    "                #                                   [max_time_step + 1, batch_size, num_decoder_symbols] if output_time_major=True\n",
    "                # decoder_outputs_train.sample_id: [batch_size], tf.int32\n",
    "                (self.decoder_outputs_train, self.decoder_last_state_train, \n",
    "                self.decoder_outputs_length_train) = (seq2seq.dynamic_decode(\n",
    "                decoder=training_decoder,\n",
    "                output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=max_decoder_length))\n",
    "                    \n",
    "                    \n",
    "                # More efficient to do the projection on the batch-time-concatenated tensor\n",
    "                # logits_train: [batch_size, max_time_step + 1, num_decoder_symbols]\n",
    "                # self.decoder_logits_train = output_layer(self.decoder_outputs_train.rnn_output)\n",
    "                self.decoder_logits_train = tf.identity(self.decoder_outputs_train.rnn_output) \n",
    "                # Use argmax to extract decoder symbols to emit\n",
    "                self.decoder_pred_train = tf.argmax(self.decoder_logits_train, axis=-1,\n",
    "                                                        name='decoder_pred_train')\n",
    "                    \n",
    "                # masks: masking for valid and padded time steps, [batch_size, max_time_step + 1]\n",
    "                masks = tf.sequence_mask(lengths=self.decoder_inputs_length, \n",
    "                                         maxlen=max_decoder_length, dtype=self.dtype, name='masks')\n",
    "\n",
    "                # Computes per word average cross-entropy over a batch\n",
    "                # Internally calls 'nn_ops.sparse_softmax_cross_entropy_with_logits' by default\n",
    "                self.loss = seq2seq.sequence_loss(logits=self.decoder_logits_train, \n",
    "                                                  targets=self.decoder_targets,\n",
    "                                                  weights=masks,\n",
    "                                                  average_across_timesteps=True,\n",
    "                                                  average_across_batch=True,)\n",
    "                # Training summary for the current batch_loss\n",
    "                    \n",
    "                # Training summary for the current batch_loss\n",
    "                tf.summary.scalar('loss', self.loss)\n",
    "\n",
    "                # Contruct graphs for minimizing loss\n",
    "                self.init_optimizer()\n",
    "                 \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model..\n",
      "building model..\n",
      "Building Encoder..\n",
      "Building decoder and attention...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Seq2SeqModel' object has no attribute 'attention_mechanism'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d51d47e0370b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-818a0a01b25c>\u001b[0m in \u001b[0;36mbuild_decoder\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[1;31m#Recheck this code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder_cell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder_initial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_decoder_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;31m#Instantiating pretrained embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-818a0a01b25c>\u001b[0m in \u001b[0;36mbuild_decoder_cell\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m         self.decoder_cell_list[-1] = attention_wrapper.AttentionWrapper(\n\u001b[0;32m    137\u001b[0m         \u001b[0mcell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder_cell_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mattention_mechanism\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention_mechanism\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0mattention_layer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mcell_input_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattn_decoder_input_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Seq2SeqModel' object has no attribute 'attention_mechanism'"
     ]
    }
   ],
   "source": [
    "#Testing Seq2Seq\n",
    "reset_graph()\n",
    "\n",
    "config ={'cell_type': 'lstm',\n",
    "         'hidden_units': 64 ,\n",
    "         'depth': 2,\n",
    "         'attention_type': 'bahdanou',\n",
    "          'embedding_size': 50,\n",
    "           'use_residual': True,\n",
    "          'attn_input_feeding': False ,\n",
    "           'use_dropout': True,\n",
    "        'dropout_rate' : 0.3,\n",
    "        'optimizer' : 'Adam',\n",
    "        'learning_rate' : 0.001,\n",
    "        'max_gradient_norm': 1.0,\n",
    "        'use_float16': False,\n",
    "        'beam_width': 3,\n",
    "        'max_decode_sep': 18 }\n",
    "\n",
    "\n",
    "obj = Seq2SeqModel(config,'train')\n",
    "obj.build_model()\n",
    "obj.build_encoder()\n",
    "obj.build_decoder()\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    eie,enc_outputs,enc_laststate=sess.run([obj.encoder_inputs_embedded,obj.encoder_outputs,obj.encoder_last_state], \n",
    "                                                   feed_dict={obj.encoder_embedding_placeholder:emb ,\n",
    "                                                              obj.encoder_inputs:eInput, \n",
    "                                                              obj.encoder_inputs_length: eLengths,\n",
    "                                                              obj.keep_prob_placeholder : 0.3 })\n",
    "    print('encoder Outputs:',enc_outputs.shape)\n",
    "    print(enc_outputs)\n",
    "    print()\n",
    "    print('Encoder last state:',len(enc_laststate))\n",
    "    print(enc_laststate)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
